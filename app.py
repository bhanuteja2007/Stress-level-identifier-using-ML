# -*- coding: utf-8 -*-
"""project for stress level-1.pkl

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YuEU_WNNDHzx_UpmBxRDbnPb2FIg1nhv
"""
from flask import Flask
app = Flask(__name__)

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.linear_model import LinearRegression



df = pd.read_csv('stress.csv', sep=';')

df.head()

df.info()

df.isnull().sum().sum()

df.dropna(inplace=True)

df.isnull().sum()

dfDUPData=df[df.duplicated()]

dfDUPData

df.drop_duplicates(inplace=True)

df.duplicated().sum()

df.shape

import plotly.express as px

colList=df.columns

for x in colList:
  if df[x].dtype != 'object':
    fig = px.box(df[x],title = f'Box plot of {x} Column')
    fig.show()

df.columns

from sklearn.linear_model import LogisticRegression

outCols = ['mental_health_history','headache','blood_pressure']

catCol = []
for x in df.columns:
  if df[x].dtype == 'object':
    catCol.append(x)

catCol

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
lableMap = {}
for x in catCol:
  df[x] = le.fit_transform(df[x])
  lableMap[x] = dict(zip(le.classes_, le.transform(le.classes_)))
  print(f'Mapped for {x}: {lableMap[x]}')

df.head()

print(df.columns)

print(df.columns)

df = pd.read_csv('/content/StressLevelDataset (1).csv', delimiter=',')

print(df.columns)

print(df.columns.tolist())

X = df.drop(columns=['stress_level'])  # Input features
y = df['stress_level']                 # Target variable

print(X.head())  # Preview input features
print(y.head())  # Preview target labels

x = df.drop(columns=['anxiety_level','headache'])

X

X = df.drop(columns=['stress_level'])  # Input features
y = df['stress_level']                 # Target variable

y = df['stress_level']  # âœ… This works

y

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x,y,train_size = 0.8,random_state=42)

x_train

x_test

model = LogisticRegression(max_iter=1000)

model.fit(x_train,y_train)

y_pred = model.predict(x_test)

y_pred

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

accuracy_score(y_test,y_pred)

confusion_matrix(y_test,y_pred)

print(classification_report(y_test,y_pred))

def sigmoid(x):
  result = 1/(1+np.exp(-x))
  return result

y_score = model.predict_proba(x_test)[:,1]

sorInd = np.argmax(y_score)

sorInd

sortLable = y_test.iloc[sorInd]

sortLable

sortScore = y_score[sorInd]

x_value = np.linspace(-10,10,100)
y_sigmoid = sigmoid(x_value)

y_sigmoid

plt.plot(x_value, y_sigmoid,color = 'red')
plt.axhline(y=0.5, color = 'Blue', linestyle = '--')
plt.scatter(sortScore,sortLable)
plt.plot()

from sklearn.metrics import classification_report

print(classification_report(y_test, model.predict(x_test)))

accuracy = model.score(x_test, y_test)
print(f"Accuracy: {accuracy:.2f}")

from sklearn.metrics import classification_report
print(classification_report(y_test, model.predict(x_test)))

from sklearn.model_selection import cross_val_score
scores = cross_val_score(model, x, y, cv=5)
print("Cross-validation scores:", scores)
print("Average score:", scores.mean())

import matplotlib.pyplot as plt

# Example: cross-validation scores
scores = [1.0,1.0,0.99090909,0.99545455,0.99090909]

plt.figure(figsize=(8, 5))
plt.bar(range(1, len(scores)+1), scores, color='skyblue')
plt.ylim(0.95, 1.01)
plt.xlabel('Fold')
plt.ylabel('Accuracy')
plt.title('Cross-Validation Accuracy per Fold')
plt.grid(True)
plt.show()

from google.colab import drive
drive.mount('/content/drive')

import joblib

from sklearn.linear_model import LogisticRegression

# Sample training data
X = [[0, 0], [1, 1]]  # Features
y = [0, 1]            # Labels

# Create and train the model
model = LogisticRegression()
model.fit(X, y)

print(model.predict([[2, 2]]))  # Output will be [1] or [0] depending on learned weights

import joblib
joblib.dump(model, '/content/drive/MyDrive/Colab Notebooks/model.pkl')

from flask import Flask, request, jsonify
import joblib
import numpy as np

app = Flask(__name__)

# Load your trained model
model = joblib.load('/content/drive/MyDrive/Colab Notebooks/model.pkl')  # Make sure model.pkl is in the same folder

@app.route('/')
def home():
    return "Stress Level Prediction API is running!"

@app.route('/predict', methods=['POST'])
def predict():
    data = request.get_json(force=True)
    features = np.array(data['features']).reshape(1, -1)
    prediction = model.predict(features)
    return jsonify({'prediction': int(prediction[0])})

requirements = """
flask
joblib
numpy
scikit-learn
gunicorn
pandas
"""

# Save it to your Drive
with open('/content/drive/MyDrive/Colab Notebooks/requirements.txt', 'w') as f:
    f.write(requirements.strip())

from google.colab import files
files.download('/content/drive/MyDrive/Colab Notebooks/model.pkl')

files.download('/content/drive/MyDrive/Colab Notebooks/requirements.txt')

import pandas as pd
df = pd.read_csv('StressLevelDataset (1).csv')  # Make sure the filename matches exactly

import pandas as pd
df = pd.read_csv('StressLevelDataset (1).csv')  # Make sure the filename matches exactly

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/StressLevelDataset (1).csv')

from google.colab import drive
drive.mount('/content/drive')

from google.colab import files
uploaded = files.upload()

import pandas as pd
df = pd.read_csv('StressLevelDataset (1).csv')

print(df.shape)
print(df.head())



